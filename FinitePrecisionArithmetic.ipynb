{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567a4d2e",
   "metadata": {},
   "source": [
    "## Floating Point Representation: A Discussion\n",
    "---\n",
    "\n",
    "References:\n",
    "- What every programmer should know about floating point arithmetic?[Article web reprint by David Goldberg](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)\n",
    "- What every programmer should know about floating point arithmetic? [More accessible web article](https://floating-point-gui.de/)\n",
    "- A [good summary](https://www.volkerschatz.com/science/float.html) of the first reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6446fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(0.1+0.2==0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be0e85",
   "metadata": {},
   "source": [
    "**Example** What should be the output of $x_{20}$ when $x_1 = 1/10$ and $x_{n+1}  =f(x_n)$.\n",
    "\n",
    "[Following Example Source](https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb#Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d829eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x <= 0.5:\n",
    "        return 2 * x\n",
    "    else:\n",
    "        return 2*x - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d692777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.2\n",
      "0.4\n",
      "0.8\n",
      "0.6000000000000001\n",
      "0.20000000000000018\n",
      "0.40000000000000036\n",
      "0.8000000000000007\n",
      "0.6000000000000014\n",
      "0.20000000000000284\n",
      "0.4000000000000057\n",
      "0.8000000000000114\n",
      "0.6000000000000227\n",
      "0.20000000000004547\n",
      "0.40000000000009095\n",
      "0.8000000000001819\n",
      "0.6000000000003638\n",
      "0.2000000000007276\n",
      "0.4000000000014552\n",
      "0.8000000000029104\n"
     ]
    }
   ],
   "source": [
    "x = 0.1\n",
    "for i in range(20):\n",
    "    print(x)\n",
    "    x = f(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11159662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "#YouTubeVideo(\"gp_D8r-2hwk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c14625",
   "metadata": {},
   "source": [
    "## IEEE 754 Normalized Binary Form\n",
    "---\n",
    "Represents numbers in float-64 in the following way\n",
    "$$\\Large\n",
    "(-1)^s \\left( 1+ f\\right) \\times 2^{e-1023}\n",
    "$$\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/IEEE_754_Double_Floating_Point_Format.svg/2560px-IEEE_754_Double_Floating_Point_Format.svg.png\" width=\"800xp\" />\n",
    "\n",
    "[Image](https://en.wikipedia.org/wiki/Double-precision_floating-point_format#/media/File:IEEE_754_Double_Floating_Point_Format.svg)\n",
    "\n",
    ">- One sign bit, denoted by s.\n",
    ">- Biased exponent, e, takes 11 bits.\n",
    ">- The fractional part (mantissa), f, in the normalized form takes 52 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e544af",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\\begin{aligned}\n",
    "(152.356425)_{10} &= (1001 1000 .0101 1011 0011 1110 10101 0110 0110 1100 1111 0100 0010)_2\\\\\n",
    "&= (1.0011~0000~1011~0110~0111~1101~0101~0110~0110~1100~1111~0100~0010)_2 \\times 2^7\n",
    "\\end{aligned}\n",
    "\n",
    "On comparison with the standard form, we have $e-1023 = 7$, implying that the biased exponent is $$e = 1030 = (1000 0000 110)_2.$$ \n",
    "The sign bit should be 0 for a positive number. And the fractional part is   \n",
    "$$f=.0011~0000~1011~0110~0111~1101~0101~0110~0110~1100~1111~0100~0010$$\n",
    "Hence $ 152.356425$ in 64-bits is given by\n",
    " $$ {\\color{blue}{0}} ~{\\color{green}{100~0000~0110}}~ {\\color{pink}{0011~0000~1011~0110~0111~1101~0101~0110~0110~1100~1111~0100~0010}}$$ \n",
    "(That is  4063 0B67 D566 CF42 in hexadecimal representation. How? Make groups of four bits to get 16 hexadecimal numbers. For example 0100 is 4, 1111 is F, and so on.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd94ef2e",
   "metadata": {},
   "source": [
    "### Special Encodings in float64\n",
    "\n",
    "- The biased exponent for decimal numbers satisfy: $-1023 < e -1023 < 1024$, or $0<e<2047$.\n",
    "\n",
    "- The  value $e=0$ is reserved for some special cases.\n",
    "  >- When $e=0$ (all zero bits) with $f=0$, it represents **plus or minus zero**. \n",
    "  >- When $e=0$ with $f \\ne 0$, it represents **subnormals** that are small numbers quite close to zero, even smaller than the smallest normalized binary numbers. They are used to handle underflow in floating point arithmetics.\n",
    "\n",
    "- The value $e=2047$ is reserved for some special cases.\n",
    ">- When $e = 2047$ (all 1 bits) with $f=0$, it represent **plus or minus infinity**\n",
    ">- When $e=2047$ (all 1 bits) and $f \\ne 0$, it represents  **NaN** (not a number)\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<strong>Overflow</strong>: When the resulting number from some mathematical operation is larger then the largest possible number in float 64 ($\\approx 10^{308}$ in magnitude), we say that an overflow has occurred.\n",
    "<br>\n",
    "<strong>Underflow</strong>: When the result of an arithmetic operation is quite close to zero beyond the normalized representation in float 64 (smaller than $\\approx 10^{-308}$ in magnitude), it is called an underflow.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83962839",
   "metadata": {},
   "source": [
    "Similarly, float-32 is given in the following way\n",
    "$$\\Large\n",
    "(-1)^s \\left( 1+ f\\right) \\times 2^{e-127}\n",
    "$$\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Float_example.svg/2560px-Float_example.svg.png\" width=\"800xp\" />\n",
    "\n",
    "[Image](https://en.wikipedia.org/wiki/Double-precision_floating-point_format#/media/File:IEEE_754_Double_Floating_Point_Format.svg)\n",
    "\n",
    ">- One sign bit, denoted by s.\n",
    ">- Biased exponent, e, takes 8 bits.\n",
    ">- The fractional part (mantissa), f, in the normalized form takes 23 bits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb1cf5",
   "metadata": {},
   "source": [
    "### Error Analysis with Floating Point Representation\n",
    "\n",
    "\n",
    "In general, a real number $x$ can not be represented exactly in a floating point systems such as IEEE-754. Let $fl[x]$ be the floating point representation of $x$, Then\n",
    "$$\n",
    " fl[x] = x(1+\\delta),\\ \\text{ where }  \\quad |\\delta | =\\left|\\dfrac{fl(x)-x}{x}\\right| \\le \\epsilon \n",
    " $$\n",
    " where $\\delta$ is the relative error and  $\\epsilon$  represent the unit round-off error (or machine precision $\\approx 10^{-16}$ in float64).\n",
    " \n",
    " <div class=\"alert alert-block alert-info\">\n",
    "  If $x$ and $y$ are machine numbers and $\\odot$ is some floating poin operation ($+,-,\\times, \\div$) between them, then\n",
    "  $$\n",
    "  fl[x\\odot  y] = (x \\odot y) (1 + \\delta), \\text{ where } \\quad |\\delta| \\leq \\epsilon\n",
    "  $$\n",
    "  \n",
    "  which could alternatively be written as\n",
    "  $$\n",
    "  fl[x\\odot  y] = (x + \\delta_1)\\odot (y + \\delta_2).\n",
    "  $$\n",
    "  This is an example of a backward error analysis where $fl[x\\odot  y]$ could be seen as the exact result of slightly perturbed data.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afbcd5",
   "metadata": {},
   "source": [
    "### Loss of Precision\n",
    "\n",
    "**Loss of Precision**: Subtraction of two nearly equal  numbers on a finite precision machine leads to loss of significance due to cancellation of significant digits and can lead to disastrous errors in calculations.\n",
    " \n",
    "**Remedy for loss of precision**: Use higher precision arithmetic or reformulate the calculation to avoid such subtractions. Use rationalization of radicals, Taylor polynomial approximation, for example, if possible.\n",
    "\n",
    "**EXAMPLE** Write the following expressions in ways that avoid the loss of significance due to subtraction of close quantities.\n",
    "\n",
    "(A) $f(x) = \\sqrt{x+1/x} - \\sqrt{x - 1/x}.$\n",
    "\n",
    "(B) $f(x) = \\tan{x} - \\sin{x}.$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be11fd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger \"><strong> Loss of Precision Theorem</strong>\n",
    "    Let $x$ and $y$ be normalized floating-point machine numbers, where $x>y>0$. \n",
    "    If we have $$2^{-p} \\le 1-\\dfrac{y}{x}\\le 2^{-q}$$ for some positive integers $p$ and $q$, then at most $p$ and at least $q$ significant binary bits are lots in the subtraction $y-x$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa1282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  3.33333333e-01  1.11111111e-01  3.70370370e-02\n",
      "   1.23456790e-02  4.11522634e-03  1.37174211e-03  4.57247371e-04\n",
      "   1.52415789e-04  5.08052602e-05  1.69350748e-05  5.64497734e-06\n",
      "   1.88146872e-06  6.26394672e-07  2.05751947e-07  5.63988754e-08\n",
      "  -2.99408028e-08 -2.04941979e-07 -8.48160840e-07 -3.40210767e-06\n",
      "  -1.36115854e-05 -5.44473934e-05 -2.17789924e-04 -8.71159813e-04\n",
      "  -3.48463929e-03 -1.39385572e-02 -5.57542287e-02 -2.23016915e-01\n",
      "  -8.92067659e-01 -3.56827064e+00 -1.42730825e+01 -5.70923302e+01\n",
      "  -2.28369321e+02 -9.13477283e+02 -3.65390913e+03 -1.46156365e+04\n",
      "  -5.84625461e+04 -2.33850184e+05 -9.35400738e+05 -3.74160295e+06]]\n"
     ]
    }
   ],
   "source": [
    "# The following difference equation has the solution x_n  =1/3^n. \n",
    "import numpy as np\n",
    "x=np.zeros((40,1),dtype=float)\n",
    "x[0]=1.0\n",
    "x[1]=1.0/3\n",
    "for n in range(1,39):\n",
    "    x[n+1]= (13.0/3.0) * x[n] - (4.0/3.0) * x[n-1]\n",
    "\n",
    "print(x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f6007d",
   "metadata": {},
   "source": [
    "What is your observations from the above iteration?\n",
    "\n",
    "---\n",
    "\n",
    "We say that a numerical process is <span style=\"color:red\">unstable</span> if small error at one stage of the process are magnified in subsequent stages and seriously degrade the accuracy of the overall calculation.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Condition or conditioning**  indicates sensitivity of a solution to  a problems with small relative change in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28eda4b",
   "metadata": {},
   "source": [
    "#### Care that should be taken while writing numerical algorithms\n",
    "---\n",
    ">- Loss of precision: avoid subtraction of close quantities by mathematical manipulations.\n",
    ">- Minimize the introduction of roundoff errors.\n",
    ">- Be careful converting large integers.\n",
    ">- Extra care when iteration is being used.\n",
    ">- Minimize truncation errors in mathematical terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef87240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
